
# Manual de Instalaci√≥n del Sistema

Este documento describe paso a paso c√≥mo instalar y poner en funcionamiento el sistema desde un entorno limpio, basado en Ubuntu Server y utilizando contenedores Docker. Est√° basado en los comandos ejecutados durante la puesta en marcha del trabajo.

---

## ‚úÖ Requisitos previos

El despliegue del sistema va a requerir lo siguiente:

- **Docker** versi√≥n 20 o superior
- **Docker Compose** versi√≥n 2 o superior (integrado en Docker Desktop o como plugin)
- **Git** para clonar el repositorio
- Acceso a puertos locales:
  - `5173`: interfaz web del dashboard
  - `8080`: panel de control de Airflow
  - `5601`: acceso a Kibana
  - `9200`: servicio de Elasticsearch


## üõ†Ô∏è Instalaci√≥n de dependencias necesarias

```bash
sudo apt-get update
sudo apt-get install \
    ca-certificates \
    curl \
    gnupg \
    lsb-release
```

### Configurar repositorio oficial de Docker:

```bash
sudo mkdir -p /etc/apt/keyrings
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | \
    sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg

echo \
  "deb [arch=$(dpkg --print-architecture) \
  signed-by=/etc/apt/keyrings/docker.gpg] \
  https://download.docker.com/linux/ubuntu \
  $(lsb_release -cs) stable" | \
  sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

sudo apt-get update
```

### Instalar Docker y complementos:

```bash
sudo apt-get install docker-ce docker-ce-cli containerd.io docker-compose-plugin
```

> Verificar instalaci√≥n:

```bash
docker --version
docker compose version
```

---

## üìÅ Clonaci√≥n del repositorio y preparaci√≥n del entorno

```bash
cd /opt
sudo mkdir malwarebi
sudo chown $USER:$USER malwarebi
cd malwarebi

git clone https://github.com/cbarret276/TFM.git .
```

## üîê Configuraci√≥n de variables de entorno

Algunos contenedores requieren ficheros de configuraci√≥n. 

Para Airflow se requiere un fichero `.env_airflow` en la ra√≠z del proyecto con las claves de acceso a APIs externas (Triage, ThreatFox) y la configuaci√≥n del planificador (paralelismo). 

```.env_airflow
TRIAGE_API_KEY=your_key_here
THREATFOX_API_KEY=your_key_here
AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=
AIRFLOW__CORE__EXECUTOR=LocalExecutor
AIRFLOW__CORE__PARALLELISM=4
AIRFLOW__CORE__MAX_ACTIVE_TASKS_PER_DAG=8
AIRFLOW__CORE__MAX_ACTIVE_RUNS_PER_DAG=4
AIRFLOW__CORE__LOAD_EXAMPLES=False
```

Para la Gunicorn se necesita un fichero `.env_gunicorn` en la ra√≠z del proyecto con la siguiente configuraci√≥n

```.env_gunicorn
APP_PORT=5173
GUNICORN_RELOAD_ARG="--reload"
ELASTIC_HOST=url_here
```

Para Postgres se necesita un fichero `.env_postgres` en la ra√≠z del proyecto con la siguiente configuraci√≥n

```.env_postgres
POSTGRES_USER=user_here
POSTGRES_PASSWORD=pass_here
POSTGRES_DB=db_here
```

Estos archivos no se incluye en el repositorio por razones de seguridad. Puedes generar tus claves desde los respectivos portales de las APIs p√∫blicas.

---

## üîß 3. Despliegue de contenedores

### Construir e iniciar servicios:

```bash
docker compose up --build -d
```

> Comprobar estado:

```bash
docker compose ps
```

---

## üå¨Ô∏è Inicializaci√≥n de Apache Airflow

Acceder al contenedor:

```bash
docker compose exec airflow bash
```

Inicializar base de datos:

```bash
airflow db init
```

Crear usuario administrador:

```bash
airflow users create \
    --username your_data_here \
    --password your_data_here \
    --firstname  \
    --lastname your_data_here \
    --role Admin \
    --email your_data_here
```

Reiniciar el contenedor:

```bash
exit
docker compose restart airflow
```

---

## üìä 5. Comprobaci√≥n de funcionamiento

Comprobar logs de servicios:

```bash
docker compose logs -f airflow
docker compose logs -f elasticsearch
docker compose ps
```

---


## üß† Notas finales

- Si se transfiere una carpeta `data` de otro entorno para Elasticsearch, puede dar errores de permisos: se recomienda limpiarla y permitir que se regenere.


---

## ‚úÖ Servicios por defecto

| Servicio     | URL                        |
|--------------|----------------------------|
| Dashboard    | http://localhost:8050      |
| Airflow      | http://localhost:8080      |
| Elasticsearch| http://localhost:9200      |
| Kibana       | http://localhost:5601      |


## ‚úÖ Comprobaci√≥n

Para verificar que todo funciona:

1. Accede a http://localhost:5173 y comprueba que se carga la interfaz.
2. En Airflow, verifica que los DAGs est√°n disponibles y programados.
3. Comprueba que Kibana se conecta al √≠ndice `bronze_mw_raw`.
4. Aseg√∫rate de que los filtros en el dashboard muestran datos reales.


Este proceso est√° dise√±ado para ser reproducible en cualquier entorno compatible con Docker, sin necesidad de instalaci√≥n adicional de dependencias ni configuraci√≥n avanzada.


---

## ‚öôÔ∏è Personalizaci√≥n opcional

El fichero `docker-compose.yml` permite modificar puertos, versiones o vol√∫menes si deseas adaptarlo a entornos espec√≠ficos.

---

## üß™ Alternativa: ejecuci√≥n local para desarrollo

Si solo deseas ejecutar el dashboard puedes hacerlo en modo desarrollo:

```bash
cd dash_app
python -m venv venv
source venv/bin/activate   # En Windows: venv\Scripts\activate
pip install -r requirements.txt
python App.py
```

‚ö†Ô∏è Para que funcione correctamente, necesitas tener un servidor Elasticsearch accesible en `localhost:9200` o configurarlo en `app_instance.py`.
