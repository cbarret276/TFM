# 02 - Manual de Instalaci√≥n

Este documento describe el proceso de instalaci√≥n y despliegue de **MalwareBI**, una plataforma contenerizada para el an√°lisis visual de malware, desarrollada como parte de un Trabajo de Fin de M√°ster en Ciencia de Datos (UNED). La soluci√≥n se ejecuta de forma local utilizando Docker y Docker Compose.

---

## ‚úÖ Requisitos previos

Antes de instalar el sistema, aseg√∫rese de disponer de lo siguiente:

- **Docker** versi√≥n 20 o superior
- **Docker Compose** versi√≥n 2 o superior (integrado en Docker Desktop o como plugin)
- **Git** para clonar el repositorio
- Acceso a puertos locales:
  - `5173`: interfaz web del dashboard
  - `8080`: panel de control de Airflow
  - `5601`: acceso a Kibana
  - `9200`: servicio de Elasticsearch

---

## üì¶ Clonaci√≥n y despliegue

Siga los siguientes pasos desde la terminal:

```bash
git clone https://github.com/cbarret276/TFM.git
cd TFM
docker compose up --build
```

Esto descargar√° el c√≥digo, construir√° las im√°genes necesarias y levantar√° los contenedores definidos en `docker-compose.yml`.

---

## üåê Acceso a los servicios desplegados

Una vez iniciado, podr√° acceder a los distintos servicios a trav√©s del navegador:

| Servicio       | URL                   |
|----------------|------------------------|
| Dashboard      | http://localhost:5173 |
| Airflow        | http://localhost:8080 |
| Elasticsearch  | http://localhost:9200 |
| Kibana         | http://localhost:5601 |

---

## üîê Configuraci√≥n de variables de entorno

Algunos contenedores requieren ficheros de configuraci√≥n. 

Para Airflow se requiere un fichero `.env_airflow` en la ra√≠z del proyecto con las claves de acceso a APIs externas (Triage, ThreatFox) y la configuaci√≥n del planificador (paralelismo). 

```.env_airflow
TRIAGE_API_KEY=your_key_here
THREATFOX_API_KEY=your_key_here
AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=
AIRFLOW__CORE__EXECUTOR=LocalExecutor
AIRFLOW__CORE__PARALLELISM=4
AIRFLOW__CORE__MAX_ACTIVE_TASKS_PER_DAG=8
AIRFLOW__CORE__MAX_ACTIVE_RUNS_PER_DAG=4
AIRFLOW__CORE__LOAD_EXAMPLES=False
```

Para la Gunicorn se necesita un fichero `.env_gunicorn` en la ra√≠z del proyecto con la siguiente configuraci√≥n

```.env_gunicorn
APP_PORT=5173
GUNICORN_RELOAD_ARG="--reload"
ELASTIC_HOST=url_here
```

Para Postgres se necesita un fichero `.env_postgres` en la ra√≠z del proyecto con la siguiente configuraci√≥n

```.env_postgres
POSTGRES_USER=user_here
POSTGRES_PASSWORD=pass_here
POSTGRES_DB=db_here
```

Estos archivos no se incluye en el repositorio por razones de seguridad. Puedes generar tus claves desde los respectivos portales de las APIs p√∫blicas.

---

## ‚öôÔ∏è Personalizaci√≥n opcional

El fichero `docker-compose.yml` permite modificar puertos, versiones o vol√∫menes si deseas adaptarlo a entornos espec√≠ficos.

---

## üß™ Alternativa: ejecuci√≥n local para desarrollo

Si solo deseas ejecutar el dashboard puedes hacerlo en modo desarrollo:

```bash
cd dash_app
python -m venv venv
source venv/bin/activate   # En Windows: venv\Scripts\activate
pip install -r requirements.txt
python App.py
```

‚ö†Ô∏è Para que funcione correctamente, necesitas tener un servidor Elasticsearch accesible en `localhost:9200` o configurarlo en `app_instance.py`.

---

## ‚úÖ Comprobaci√≥n

Para verificar que todo funciona:

1. Accede a http://localhost:5173 y comprueba que se carga la interfaz.
2. En Airflow, verifica que los DAGs est√°n disponibles y programados.
3. Comprueba que Kibana se conecta al √≠ndice `bronze_mw_raw`.
4. Aseg√∫rate de que los filtros en el dashboard muestran datos reales.

---

Este proceso est√° dise√±ado para ser reproducible en cualquier entorno compatible con Docker, sin necesidad de instalaci√≥n adicional de dependencias ni configuraci√≥n avanzada.


